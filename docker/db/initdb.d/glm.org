* GOES GLM Lightning
#+PROPERTY: header-args:sql :engine postgresql :cmdline "service=glm" :tangle yes

The GLM Lightning product needs to be imported from some CSV files.


First, let's put all our data into a glm schema

#+BEGIN_SRC sql
drop schema if exists glm cascade;
create schema glm;
#+END_SRC

#+RESULTS:
| DROP SCHEMA   |
|---------------|
| CREATE SCHEMA |

Currently we have GOES16 and GOES17 data.

#+BEGIN_SRC sql
create type platform_type as ENUM('G16','G17');
#+END_SRC

#+RESULTS:
| CREATE TYPE |
|-------------|

The dataset table primarily stores the start and stop times for the datasets.
These are used to create exact times for the flashes.  We'll also validate that
we never add the same datasets twice.  I don't know that dataset names are
included, and we need to verify the dataset id is the same.

#+BEGIN_SRC sql
create table glm.dataset (
       dataset_id uuid primary key,
       platform_id platform_type not null,
       dataset_name text unique,
       date_created timestamp not null,
       time_coverage_start timestamp not null,
       time_coverage_end timestamp not null
       );
#+END_SRC

#+RESULTS:
| CREATE TABLE |
|--------------|

#+BEGIN_SRC sql
create table glm.flash (
 flash_id integer not null,
 dataset_id uuid references glm.dataset,
 time_offset_of_first_event integer,
 time_offset_of_last_event integer,
 lat float,
 lon float,
 area integer,
 energy integer,
 quality_flag integer);

create index flash_dataset_id on flash(dataset_id);

#+END_SRC

#+RESULTS:
| CREATE TABLE |
|--------------|

As an aside, these [[https://www.postgresqltutorial.com/postgresql-indexes/postgresql-list-indexes/][Index Examples]] show how you can get a quick view of the
indexes that you do have.


#+BEGIN_SRC sql :tangle no
select tablename,indexname,indexdef
from pg_indexes
where schemaname='glm';
#+END_SRC

#+RESULTS:
| tablename | indexname                | indexdef                                                                               |
|-----------+--------------------------+----------------------------------------------------------------------------------------|
| dataset   | dataset_pkey             | CREATE UNIQUE INDEX dataset_pkey ON glm.dataset USING btree (dataset_id)               |
| dataset   | dataset_dataset_name_key | CREATE UNIQUE INDEX dataset_dataset_name_key ON glm.dataset USING btree (dataset_name) |
| flash     | flash_dataset_id         | CREATE INDEX flash_dataset_id ON glm.flash USING btree (dataset_id)                    |

** Dataset Functions

*** Energy and Area

We need a couple of functions to convert the quantized data to actual
datasets. Using the [[https://www.ncdc.noaa.gov/gridsat/conusgoes-index.php?name=howto][NOAA FAQ]] and expecting it to be the same for all data, we
use the above for our energy and area.  Energy is is Joules and area is in m2.


#+BEGIN_SRC sql
create or replace function energy_J (f in glm.flash, out J float)
LANGUAGE SQL IMMUTABLE AS $$
select (f.energy::float * 9.99996e-16) + 2.8515e-16 as J;
$$;

create or replace function area_m2 (f in glm.flash, out m2 float)
LANGUAGE SQL IMMUTABLE AS $$
select (f.energy::float * 152601.9) as m2;
$$;

#+END_SRC

#+RESULTS:
| CREATE FUNCTION |
|-----------------|
| CREATE FUNCTION |


*** Location

We convert the Latitude / Longitude into a centroid.  We aren't exactly sure
about the sphereoid for the lat,lon.  Here we are assuming it's WGS84, which is
what's used for the projected GOES grids.

#+BEGIN_SRC sql
create or replace function centroid (f in glm.flash, out centroid geometry(Point,4326))
LANGUAGE SQL IMMUTABLE AS $$
select st_setsrid(ST_MakePoint(f.lon,f.lat),4326) as centroid;
$$;

#+END_SRC

#+RESULTS:
| CREATE FUNCTION |
|-----------------|

We could conceivably use the area to create bigger regions, but it's unclear to
me the best way to do that, so for now we'll just stick w/ centroid as our only
point.  Later, we *could* use the event grid points, but not sure how helpful
that would be.

*** Duration

Finally, we need to create the duration of the

#+BEGIN_SRC sql
create or replace function start_time (f in glm.flash, out t timestamp)
LANGUAGE SQL IMMUTABLE AS $$
with o as ( select time_coverage_start as s
 from glm.dataset where dataset_id=f.dataset_id
)
select o.s+(((f.time_offset_of_first_event * 0.0003814756 ) -5) || ' seconds')::interval as t
from o;
$$;

create or replace function stop_time (f in glm.flash, out t timestamp)
LANGUAGE SQL IMMUTABLE AS $$
with o as ( select time_coverage_start as s
 from glm.dataset where dataset_id=f.dataset_id
)
select o.s+(((f.time_offset_of_last_event * 0.0003814756 ) -5) || ' seconds')::interval as t
from o;
$$;

#+END_SRC

#+RESULTS:
| CREATE FUNCTION |
|-----------------|
| CREATE FUNCTION |


**** Duration Index

Now we can use these functions to describe indices over our complete range of
flashes.  For example

#+BEGIN_SRC sql :tangle no
create index flash_start_time on flash(start_time(flash));
#+END_SRC

And verify this is used by comparing a query on the start_time vs. the
stop_time.  The difference using the index scan is very considerable (orders of magnitude)

#+name:explain_start
#+BEGIN_SRC sql :tangle no
explain select
 f.energy_J,f.area_m2,st_asEWKT(f.centroid),f.start_time,f.stop_time
from flash f
where '2021-05-28'::date < f.start_time
and f.start_time < '2021-05-29'::date;
#+END_SRC

#+RESULTS: explain_start
| QUERY PLAN                                                                                      |
|-------------------------------------------------------------------------------------------------|
| Index Scan using flash_start_time on flash f  (cost=0.56..776087.85 rows=218319 width=64)       |
| Index Cond: ((start_time(f.*) > '2021-05-28'::date) AND (start_time(f.*) < '2021-05-29'::date)) |
| JIT:                                                                                            |
| Functions: 3                                                                                    |
| Options: Inlining true, Optimization true, Expressions true, Deforming true                     |


#+name:explain_stop
#+BEGIN_SRC sql :tangle no
explain select
 f.energy_J,f.area_m2,st_asEWKT(f.centroid),f.start_time,f.stop_time
from flash f
where '2021-05-28'::date < f.stop_time
and f.stop_time < '2021-05-29'::date;
#+END_SRC

#+RESULTS: explain_stop
| QUERY PLAN                                                                                |
|-------------------------------------------------------------------------------------------|
| Seq Scan on flash f  (cost=0.00..23395623.89 rows=218319 width=64)                        |
| Filter: (('2021-05-28'::date < stop_time(f.*)) AND (stop_time(f.*) < '2021-05-29'::date)) |
| JIT:                                                                                      |
| Functions: 3                                                                              |
| Options: Inlining true, Optimization true, Expressions true, Deforming true               |

Joining w/ the dataset table is actually nearly as fast as the extra index
however since the dataset table is so much smaller.  Not quite as accurate however.

#+name:explain_join
#+BEGIN_SRC sql :tangle no
explain
select f.energy_J,f.area_m2,st_asEWKT(f.centroid),f.start_time,f.stop_time
from flash f
join dataset d using (dataset_id)
where '2021-05-28'::date < d.time_coverage_start
 and d.time_coverage_start < '2021-05-29'::date;
#+END_SRC

#+RESULTS: explain_join
| QUERY PLAN                                                                                          |
|-----------------------------------------------------------------------------------------------------|
| Hash Join  (cost=27039.80..1499223.16 rows=224735 width=64)                                         |
| Hash Cond: (f.dataset_id = d.dataset_id)                                                            |
| ->  Seq Scan on flash f  (cost=0.00..932816.32 rows=43663732 width=116)                             |
| ->  Hash  (cost=26987.47..26987.47 rows=4186 width=16)                                              |
| ->  Seq Scan on dataset d  (cost=0.00..26987.47 rows=4186 width=16)                                 |
| Filter: (('2021-05-28'::date < time_coverage_start) AND (time_coverage_start < '2021-05-29'::date)) |
| JIT:                                                                                                |
| Functions: 11                                                                                       |
| Options: Inlining true, Optimization true, Expressions true, Deforming true                         |


** Views

Now, if you want to use these functions you can call them directly as in:

#+BEGIN_SRC sql :tangle no
select f.energy_J,f.area_m2,st_asEWKT(f.centroid),f.start_time,f.stop_time from flash f limit 5;
#+END_SRC

#+RESULTS:
|        energy_j |     area_m2 | st_asewkt                          | start_time                 | stop_time                  |
|-----------------+-------------+------------------------------------+----------------------------+----------------------------|
| 1.406279526e-12 | 214558271.4 | SRID=4326;POINT(-139.317 6.44349)  | 2021-01-01 15:42:01.453804 | 2021-01-01 15:42:01.573206 |
| 2.243276178e-12 | 342286061.7 | SRID=4326;POINT(-147.373 7.06065)  | 2021-01-01 15:42:11.437402 | 2021-01-01 15:42:11.628521 |
|  2.06284326e-13 |  31435991.4 | SRID=4326;POINT(-169.171 6.12735)  | 2021-01-01 15:42:17.473872 | 2021-01-01 15:42:17.627225 |
|  1.92027747e-12 |   292995648 | SRID=4326;POINT(175.772 11.2877)   | 2021-01-01 15:42:17.700469 | 2021-01-01 15:42:17.85344  |
|    4.528497e-14 |   6867085.5 | SRID=4326;POINT(-156.662 -10.8493) | 2021-01-01 15:55:45.551997 | 2021-01-01 15:55:45.743116 |

Or you could create a view as in

#+BEGIN_SRC sql :tangle no
create view flashes
 as
select f.energy_J,f.area_m2,st_asEWKT(f.centroid),f.start_time,f.stop_time
from flash f;
#+END_SRC
